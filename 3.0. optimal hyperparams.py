# -*- coding: utf-8 -*-
"""
Created on Sun Nov 17 20:38:19 2024

@author: macie
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV


from sklearn import tree
import graphviz
from IPython.display import Image
from sklearn.tree import export_graphviz
import json
import pandas as pd
import numpy as np
from utils import status_calc

shuffle_train_test = True
test_size = 0.2
features_list = ['debtequityratio', 'Price/Book', 'Revenue Per Share', 'currentratio','cashonhand', 'bookvaluepershare', 'totalliabilities', 'Market Cap']
backtest_type = 'sorted'
no_estimators_ = None

print("***************************************")
print(f'shuffle_train_test: {shuffle_train_test}')
print(f'test_size: {test_size}')
print("***************************************")
# Opening JSON file
f = open('INPUT\input_scrap.json')
# returns JSON object as a dictionary
data = json.load(f)

# Retrieve input details
# The percentage by which a stock has to beat the S&P500 to be considered a 'buy'
# Backtesting parameters
outperformance_             = data['outperform_idx'] * 100    
RandomForest_no_estimators  = data['RandomForest_no_estimators']
Backtest_initial_capital    = data['Backtest_initial_capital']
Backtest_increment          = data['Backtest_increment']
Backtest_provision          = data['Backtest_provision']
Backtest_tax_rate           = data['Backtest_tax_rate']

# Build the dataset, and drop any rows with missing values
data_df = pd.read_csv("OUTPUT/keystats_new.csv", index_col="date")
vars_ = ['Year', 'Quarter', 'Ticker', 'Close', 'SP500', 'Close_YoYpc', 'SP500_YoYpc']
len_var_basic = len(vars_)
vars_ = vars_ + features_list
data_df.dropna(axis=0, how="any", inplace=True)
data_df = data_df.replace([np.inf, -np.inf], 0)
# In case of extreme Trailing P/Es, overwrite with 0 (found in few cases)
if 'Trailing P/E' in data_df.columns:
    data_df.loc[data_df['Trailing P/E'] > 10000, 'Trailing P/E'] = 0
    data_df.loc[data_df['Trailing P/E'] < -10000, 'Trailing P/E'] = 0
data_df = data_df[vars_]
X = data_df[features_list].values

# The labels are generated by applying the status_calc to the dataframe.
# '1' if a stock beats the S&P500 by more than x%, else '0'. Here x is the
# outperformance parameter, which is set to 10 by default but can be redefined.
y = list(status_calc(data_df["Close_YoYpc"] * 100, data_df["SP500_YoYpc"] * 100, outperformance = outperformance_))

# z is required for us to track returns
z = np.array(data_df[["Close_YoYpc", "SP500_YoYpc"]])

# Generate the train set and test set by randomly splitting the dataset
# random state set the same to model init to get reproducible results
labels = data_df['Quarter'] + "_" + data_df['Ticker']
if backtest_type == 'random':
    X_train, X_test, y_train, y_test, z_train, z_test, labels_train, labels_test = train_test_split(
        X, y, z, labels, test_size = test_size, shuffle = shuffle_train_test, random_state=137
    )
else:
    train_quarters = np.unique(data_df['Quarter'])[:int((1 - test_size) * len(np.unique(data_df['Quarter'])))].tolist()
    test_quarters  = np.unique(data_df['Quarter'])[ int((1 - test_size) * len(np.unique(data_df['Quarter']))):].tolist()
    X_train = data_df[data_df['Quarter'].isin(train_quarters)][features_list].values
    X_test  = data_df[data_df['Quarter'].isin(test_quarters)][features_list].values
    y_train = y[:len(X_train)]
    y_test  = y[len(X_train):]
    z_train = z[:len(X_train)]
    z_test  = z[len(X_train):]
    labels_train = labels[:len(X_train)]
    labels_test  = labels[len(X_train):]

# Instantiate a RandomForestClassifier with 100 trees, then fit it to the training data
if no_estimators_ is not None:
    RandomForest_no_estimators = no_estimators_
     
param_grid = {
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'n_estimators': [50, 100, 200]
}

# Look for an optimal variant of Random Forest
rf = RandomForestClassifier(random_state=137)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

best_rf = grid_search.best_estimator_
print("Best hyperparameters: ", best_rf.get_params())
