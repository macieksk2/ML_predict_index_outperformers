"""
backtesting.py

1. Split train/test sets
2. Fit RF algorithm based on selected features in prev script
3. Calculate Accuracy/Precision, confusion matrix, ROC/AUC curve
4. Print out select stocks in each quarter
5. Run full backtesting of a portfolio run according to the model vs a simple strategy of buying index ETF

"""

# Preprocessing
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import json

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import cross_val_score
from sklearn import tree
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance
from sklearn.ensemble import RandomForestClassifier 
from sklearn.metrics import roc_curve, roc_auc_score 
import shap
import statsmodels.api as sm

# Tree visualization
import graphviz
from IPython.display import Image
from sklearn.tree import export_graphviz

# Make sure Graphviz is in the PATH
os.environ["PATH"] += os.pathsep + 'C:/Program Files/Graphviz/bin'
from utils import status_calc

# Change from scientific view to float
pd.set_option('display.float_format', lambda x: '%.3f' % x)

def backtest(shuffle_train_test = True, test_size = 0.2, features_list = []):
    """
    A simple backtest, which splits the dataset into a train set and test set,
    then fits a Random Forest classifier to the train set. We print the precision and accuracy
    of the classifier on the test set, then run a backtest comparing this strategy's performance
    to passive investment in the S&P500.
    Please note that there is a methodological flaw in this backtest which will give deceptively
    good results, so the results here should not encourage you to live trade.
    """
    from sklearn import tree
    import graphviz
    from IPython.display import Image
    from sklearn.tree import export_graphviz
    print("***************************************")
    print(f'shuffle_train_test: {shuffle_train_test}')
    print(f'test_size: {test_size}')
    print("***************************************")
    # Opening JSON file
    f = open('INPUT\input_scrap.json')
    # returns JSON object as a dictionary
    data = json.load(f)
    
    # Retrieve input details
    # The percentage by which a stock has to beat the S&P500 to be considered a 'buy'
    # Backtesting parameters
    outperformance_             = data['outperform_idx'] * 100    
    RandomForest_no_estimators  = data['RandomForest_no_estimators']
    Backtest_initial_capital    = data['Backtest_initial_capital']
    Backtest_increment          = data['Backtest_increment']
    Backtest_provision          = data['Backtest_provision']
    Backtest_tax_rate           = data['Backtest_tax_rate']
    
    # Build the dataset, and drop any rows with missing values
    data_df = pd.read_csv("OUTPUT/keystats_new.csv", index_col="date")
    vars_ = ['Year', 'Quarter', 'Ticker', 'Close', 'SP500', 'Close_YoYpc', 'SP500_YoYpc']
    len_var_basic = len(vars_)
    vars_ = vars_ + features_list
    data_df.dropna(axis=0, how="any", inplace=True)
    data_df = data_df.replace([np.inf, -np.inf], 0)
    # In case of extreme Trailing P/Es, overwrite with 0 (found in few cases)
    if 'Trailing P/E' in data_df.columns:
        data_df.loc[data_df['Trailing P/E'] > 10000, 'Trailing P/E'] = 0
        data_df.loc[data_df['Trailing P/E'] < -10000, 'Trailing P/E'] = 0
    data_df = data_df[vars_]
    X = data_df[features_list].values

    # The labels are generated by applying the status_calc to the dataframe.
    # '1' if a stock beats the S&P500 by more than x%, else '0'. Here x is the
    # outperformance parameter, which is set to 10 by default but can be redefined.
    y = list(status_calc(data_df["Close_YoYpc"] * 100, data_df["SP500_YoYpc"] * 100, outperformance = outperformance_))

    # z is required for us to track returns
    z = np.array(data_df[["Close_YoYpc", "SP500_YoYpc"]])

    # Generate the train set and test set by randomly splitting the dataset
    # random state set the same to model init to get reproducible results
    labels = data_df['Quarter'] + "_" + data_df['Ticker']
    X_train, X_test, y_train, y_test, z_train, z_test, labels_train, labels_test = train_test_split(
        X, y, z, labels, test_size = test_size, shuffle = shuffle_train_test, random_state=137
    )

    
    # Instantiate a RandomForestClassifier with 100 trees, then fit it to the training data
    clf = RandomForestClassifier(n_estimators = RandomForest_no_estimators, random_state=137)
    clf.fit(X_train, y_train)
    # Generate the predictions, then print test set accuracy and precision
    y_pred = clf.predict(X_test)
    print(classification_report(y_test, y_pred))
    print('*** RANDOM FORREST ***')
    print("Confusion matrix")
    print(f"{confusion_matrix(y_test, y_pred)}")
    print("Classifier performance\n", "=" * 20)
    print(f"Accuracy score: {clf.score(X_test, y_test): .2f}")
    print(f"Precision score: {precision_score(y_test, y_pred): .2f}")
    ## CONFUSION MATRIX - Get and reshape confusion matrix data
    matrix = confusion_matrix(y_test, y_pred)
    matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]
    
    # Build the plot
    plt.figure(figsize=(16,7))
    sns.set(font_scale=1.4)
    sns.heatmap(matrix, annot=True, annot_kws={'size':10},
                cmap=plt.cm.Greens, linewidths=0.2)
    
    # Add labels to the plot
    class_names = ['Not outperform', 'Outperform']
    tick_marks = np.arange(len(class_names))
    tick_marks2 = tick_marks + 0.5
    plt.xticks(tick_marks, class_names, rotation=25)
    plt.yticks(tick_marks2, class_names, rotation=0)
    plt.xlabel('Predicted label')
    plt.ylabel('True label')
    plt.title(f'Confusion Matrix for Random Forest Model, (shuffle_train_test, test_size): {shuffle_train_test, test_size}')
    plt.show()
    
    ## Feature importance, top5
    sorted_idx = clf.feature_importances_.argsort()
    plt.barh(data_df.columns[len_var_basic:][sorted_idx][-5:], clf.feature_importances_[sorted_idx][-5:])
    plt.xlabel("Random Forest Feature Importance")
    plt.show()
    # Permutation Based Feature Importance, top5
    perm_importance = permutation_importance(clf, X_test, y_test)
    sorted_idx = perm_importance.importances_mean.argsort()
    plt.barh(data_df.columns[len_var_basic:][sorted_idx][-5:], perm_importance.importances_mean[sorted_idx][-5:])
    plt.xlabel("Permutation Importance")
    plt.show()
    
    scores = cross_val_score(clf, X_test, y_test)
    print('Cross validation scores and mean:')
    print(scores)
    print(scores.mean())
    
    ## ROC AUC
    # Compute the false positive rate (FPR)  
    # and true positive rate (TPR) for different classification thresholds 
    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)
    # Compute the ROC AUC score 
    roc_auc = roc_auc_score(y_test, y_pred) 
    print("ROC AUC")
    print(roc_auc)
    # Plot the ROC curve 
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc) 
    # roc curve for tpr = fpr  
    plt.plot([0, 1], [0, 1], 'k--', label='Random classifier') 
    plt.xlabel('False Positive Rate') 
    plt.ylabel('True Positive Rate') 
    plt.title('ROC Curve') 
    plt.legend(loc="lower right") 
    plt.show()
    
    ## Plot the predicted class probabilities 
    plt.hist(y_pred.astype(int), bins=10) 
    plt.xlim(0, 1) 
    plt.title('Histogram of predicted probabilities') 
    plt.xlabel('Predicted probability of outperformance') 
    plt.ylabel('Frequency') 
    plt.show() 


    predictions = clf.predict_proba(X_test)
    # print(predictions)
    # Merge X_test, y_test and y_pred
    # Evaluate which factors affect most predicitons
    test_predict_sample = pd.DataFrame(X_test)
    test_predict_sample.columns = data_df.columns[len_var_basic:]
    test_predict_sample['y_test'] = y_test
    test_predict_sample['y_pred'] = y_pred
    test_predict_sample[['Pr_0', 'Pr_1']] = predictions
    print("Compare statistics of records predicted to under- and outperform")
    print(test_predict_sample.groupby('y_pred').mean().transpose())
    test_predict_sample['label'] = labels_test.reset_index()[0]

    # Export the first ten decision trees from the forest
    for i in range(10):
        tree = clf.estimators_[i]
        dot_data = export_graphviz(tree,
                                   feature_names = data_df.columns[len_var_basic:],  
                                   filled=True,  
                                   max_depth=2, 
                                   impurity=False, 
                                   proportion=True)
        graph = graphviz.Source(dot_data)
        display(graph)
    print('***************************')
    
    # Because y_pred is an array of 1s and 0s, the number of positive predictions is equal to the sum of the array
    num_positive_predictions = sum(y_pred)
    if num_positive_predictions < 0:
        print("No stocks predicted!")

    # Recall that z_test stores the change in stock price in column 0, and the
    # change in S&P500 price in column 1.
    # Whenever a stock is predicted to outperform (y_pred = 1), we 'buy' that stock
    # and simultaneously `buy` the index for comparison.
    
    # Merge x_test and z_test with the original dataset
    bktst = pd.DataFrame(X_test)
    bktst.columns = data_df.columns[len_var_basic:]
    bktst['Close_YoYpc'] = pd.DataFrame(z_test)[0]
    bktst['SP500_YoYpc'] = pd.DataFrame(z_test)[1]
    bktst['date']        = labels_test.reset_index()['date']
    bktst['label']       = labels_test.reset_index()[0]
    bktst['Quarter']     = [x[:6] for x in bktst['label']]
    bktst['Year']        = [int(x[:4]) for x in bktst['Quarter']]
    bktst['Q']           = [x[-2:] for x in bktst['Quarter']]
    bktst['Ticker']      = [x[7:] for x in bktst['label']]
    bktst.index          = bktst['date']
    bktst.pop('date')
    bktst = bktst.sort_values(by = 'date')
    bktst['Y_PRED']      = y_pred
    
    # Calculate the value of capital at the end of the period when:
    # Your initial capital is X USD
    # You invest each quarter Y USD
    # The stocks bought in Year t are sold in Year t + 1 and immediately reinvested
    # Provision for Buy / Sell is z%
    # Income tax is a%
    # Two strategies:
    # 1 You spread Y dollars across stocks with Y_PRED = True or put it in SP500 if none are picked this quarter
    # 2 You invest Y dollars always in SP500
    bktst['Inflow'] = bktst['Inflow min provision'] = 0
    bktst['Stocks Invested model'] = bktst['Stocks Invested Index'] = 0
    bktst['Stocks Sold value model'] = bktst['Stocks Sold value index'] = 0
    
    Initial_Capital = Backtest_initial_capital
    Increment = Backtest_increment
    prov = Backtest_provision
    tax_rate = Backtest_tax_rate 
    unq_qrts = np.unique(bktst['Quarter'])
    for i in range(len(unq_qrts)):
        # Check if there are any stocks to be picked in a given quarter
        sp500_perf = bktst[(bktst['Quarter'] == unq_qrts[i])]['SP500_YoYpc'].mean()
        if bktst[(bktst['Quarter'] == unq_qrts[i])]['Y_PRED'].sum() > 0:
            avg_perf_stk_pck = bktst[(bktst['Quarter'] == unq_qrts[i]) & (bktst['Y_PRED'] == True)]['Close_YoYpc'].mean()
        else:
            # In case of no stocks picked, buy ETF on index
            avg_perf_stk_pck = sp500_perf
        # Calculate tax if any positive returns generated
        tax_model_ = 1 * (avg_perf_stk_pck > 0)
        tax_index_ = 1 * (sp500_perf > 0)
        # Calculate capital for investment based on the initial capital at 0
        # First stocks are bought, hence provision is paid
        if i == 0:
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] = Initial_Capital
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']    = bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested model']   = bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested Index']   = bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value model'] = bktst.loc[bktst['Quarter'] == unq_qrts[i],'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value index'] = bktst.loc[bktst['Quarter'] == unq_qrts[i],'Inflow min provision']
        # Until the end of Year 1 no shares are sold
        # Add new increment each quarter
        # Accumulate the capital in Stocks Invested columns (means used since multiple rows are within each quarter)
        elif i <= 3:
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] = Increment
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']    = bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested model']   = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested model']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested Index']   = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested Index']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value model'] = bktst.loc[bktst['Quarter'] == unq_qrts[i],'Inflow min provision']
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value index'] = 0  
        # Since Year 2 onwards every quarter we sell shares / ETF on index alongside new inflows and purchases based on the model
        elif i <= 7:
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] = Increment
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']    = bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value model'] = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) * (1 + avg_perf_stk_pck * (1 - tax_rate * tax_model_)) * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value index'] = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) * (1 + sp500_perf * (1 - tax_rate * tax_index_)) * (1 - prov)  
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested model']   = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested model']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision'] - np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value model']) * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested Index']   = np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested Index']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision'] - np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value index']) * (1 - prov)
        # Since Year 3 we have the capital with accrued capital gains, which are reinvested
        else:
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow']                  = Increment
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision']    =  bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow'] * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value model'] = (np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value model']) + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) ) * (1 + avg_perf_stk_pck * (1 - tax_rate * tax_model_)) * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Sold value index'] = (np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value index']) + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Inflow min provision']) ) * (1 + sp500_perf       * (1 - tax_rate * tax_index_)) * (1 - prov)  
            # Deduct a sum of capital invested (model or index) before adding capital plus returns accumulated
            deduct_cap_inv = bktst[(bktst['Q'] == unq_qrts[i][-2:]) & (bktst['Year'] < int(unq_qrts[i][:4]))].groupby('Quarter')[['Inflow min provision']].mean().sum()[0]
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested model']   =  np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested model']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision'] - deduct_cap_inv + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value model']) * (1 - prov)
            bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Stocks Invested Index']   =  np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 1], 'Stocks Invested Index']) + bktst.loc[bktst['Quarter'] == unq_qrts[i], 'Inflow min provision'] - deduct_cap_inv + np.mean(bktst.loc[bktst['Quarter'] == unq_qrts[i - 4], 'Stocks Sold value index']) * (1 - prov)

    stock_returns         = 1 + z_test[y_pred, 0] 
    market_returns        = 1 + z_test[y_pred, 1] 
    stock_returns_not_ch  = 1 + z_test[y_pred == 0, 0] 
    market_returns_not_ch = 1 + z_test[y_pred == 0, 1] 
    print('Average model return: ', np.mean(stock_returns) - 1)
    print('Average index return: ', np.mean(market_returns) - 1)
    # Print out selected companies for trade per quarter
    for i in range(len(unq_qrts)):
        print(unq_qrts[i])
        print('Tickers')
        print(bktst[(bktst['Quarter'] == unq_qrts[i]) & (bktst['Y_PRED'] == 1)]['Ticker'].tolist())
    
    # Calculate the average growth for each stock we predicted 'buy' and the corresponding index growth
    capital_invested           = bktst.groupby('Quarter')[['Inflow']].agg('last').sum()[0]
    no_years                   = (bktst['Year'][-1] - bktst['Year'][0] + (int(bktst['Q'][-1][1]) - int(bktst['Q'][0][1])) / 4 - 1)
    ann_predicted_stock_growth = (bktst['Stocks Invested model'][-1] / capital_invested) ** (1 / no_years) - 1
    ann_index_growth           = (bktst['Stocks Invested Index'][-1] / capital_invested) ** (1 / no_years) - 1
    percentage_stock_returns   = 100 * (ann_predicted_stock_growth)
    percentage_market_returns  = 100 * (ann_index_growth)
    total_outperformance       = percentage_stock_returns - percentage_market_returns

    print("\n Stock prediction performance report \n", "=" * 40)
    print(f"Total Trades:", num_positive_predictions)
    print(f"Average return for stock predictions: {percentage_stock_returns: .1f} %")
    print(f"Average market return in the same period: {percentage_market_returns: .1f}% ")
    print(f"Compared to the index, our strategy earns {total_outperformance: .1f} percentage points more")

    bktst.groupby('Quarter')[['Stocks Invested model', 'Stocks Invested Index']].agg('last').plot()

if __name__ == "__main__":
    # Based on initial optimization routine
    backtest(shuffle_train_test = True, test_size = 0.2, features_list = ['debtequityratio', 'cashonhand_YoYpc', 'grossmargin', 'Price/Book', 'Revenue Per Share', 'currentratio', 'cashonhand', 'totalliabilities', 'bookvaluepershare'])
    # Based on revised data and scripts
    backtest(shuffle_train_test = True, test_size = 0.2, features_list = ['debtequityratio', 'Price/Book', 'Revenue Per Share', 'currentratio','cashonhand', 'bookvaluepershare', 'totalliabilities', 'Market Cap'])
